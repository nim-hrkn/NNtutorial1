{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c9ebd679-0868-44c2-a922-2b324877cfce",
   "metadata": {},
   "source": [
    "## cGAN\n",
    "\n",
    "例えば、数字をラベルとして与えて、手書き文字も生成するGANを作りたいとします。\n",
    "\n",
    "```prompt\n",
    "プロンプト「\n",
    "数字をラベルとして与えて、手書き文字生成モデルを学習するGANはどれですか。\n",
    "」\n",
    "```\n",
    "Conditional GANsがそれに対応するという回答が得られます。そしてその手法の過程の説明が出力されます。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb58f857-0794-4db4-a725-0650df82813c",
   "metadata": {},
   "source": [
    "---（回答）---\n",
    "\n",
    "数字をラベルとして手書き文字生成モデルを学習するために用いるGANの手法として、「Conditional GAN（cGAN）」が適しています。\n",
    "\n",
    "### Conditional GAN（cGAN）\n",
    "cGANは、生成器と識別器の両方に条件（ラベル）を与えることで、特定のクラスに基づいたデータ生成を可能にする手法です。以下にcGANの基本的な流れを説明します。\n",
    "\n",
    "### cGANのアーキテクチャ\n",
    "\n",
    "1. **生成器（Generator）**:\n",
    "   - 入力としてランダムノイズベクトル $ z $ とクラスラベル $ y $ を受け取り、条件付き生成画像 $ G(z|y) $ を出力します。\n",
    "   \n",
    "2. **識別器（Discriminator）**:\n",
    "   - 入力として画像 $ x $ とそのクラスラベル $ y $ を受け取り、その画像が本物か偽物かを判定します。\n",
    "\n",
    "### ステップ\n",
    "\n",
    "1. **データ準備**:\n",
    "   - 手書き文字の画像データセット（例：MNIST）に対して、各手書き数字には対応するラベル（0-9）が付与されています。\n",
    "\n",
    "2. **ラベルを条件に追加**:\n",
    "   - 生成器では、ノイズベクトルとともにラベル情報を条件として取り込む。\n",
    "   - 識別器では、画像とラベル情報が入力として利用されます。\n",
    "\n",
    "3. **トレーニング**:\n",
    "   - 生成器は条件付きで手書き文字を生成するように訓練されます。\n",
    "   - 識別器は本物の画像と生成された画像を区別するように訓練されます。\n",
    "   - 両者の競争関係により、生成器はよりリアルな手書き文字を生成する能力を獲得します。\n",
    "\n",
    "（以下略）\n",
    "\n",
    "---（回答ここまで）---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bff9d26-894c-484b-a935-b80621b970be",
   "metadata": {},
   "source": [
    "```prompt\n",
    "プロンプト「\n",
    "cGANの損失関数についておしえてください．\n",
    "」\n",
    "```\n",
    "\n",
    "以下が回答です．\n",
    "\n",
    "---（回答）---\n",
    "\n",
    "cGAN（Conditional GAN）の損失関数は、通常のGANの損失関数に「条件」（例えば、生成したい数字のラベル）を導入したものです。以下に、cGANの損失関数について詳しく説明します。\n",
    "\n",
    "### 1. **通常のGANの損失関数**\n",
    "まず、通常のGANの損失関数から説明します。通常のGANは、ジェネレーター（Generator）とディスクリミネーター（Discriminator）の2つのネットワークが競い合って学習します。\n",
    "\n",
    "- **ジェネレーターの目的**は、ディスクリミネーターを騙すような「本物に見える」偽画像を生成することです。\n",
    "- **ディスクリミネーターの目的**は、与えられた画像が本物か偽物かを正確に判定することです。\n",
    "\n",
    "損失関数は以下のように定義されます。\n",
    "\n",
    "#### 1.1 **ディスクリミネーターの損失関数**\n",
    "ディスクリミネーターは、実際の画像（本物）に対しては1を出力し、ジェネレーターが生成した画像（偽物）に対しては0を出力することを目指します。そのため、ディスクリミネーターの損失関数は次のようになります。\n",
    "\n",
    "$$\n",
    "\\mathcal{L}_D = - \\mathbb{E}_{x \\sim p_{data}(x)}[\\log D(x)] - \\mathbb{E}_{z \\sim p_z(z)}[\\log(1 - D(G(z)))]\n",
    "$$\n",
    "\n",
    "ここで、\n",
    "- $ D(x) $: 本物の画像 $ x $ に対してディスクリミネーターが出力する確率（「本物」であると判定する確率）\n",
    "- $ G(z) $: ノイズ $ z $ から生成された偽物の画像\n",
    "- $ p_{data}(x) $: 実際のデータの分布\n",
    "- $ p_z(z) $: ノイズの分布\n",
    "\n",
    "#### 1.2 **ジェネレーターの損失関数**\n",
    "ジェネレーターは、生成した画像 $ G(z) $ がディスクリミネーターに「本物」と判定されるように学習します。そのため、ジェネレーターの損失関数は次のようになります。\n",
    "\n",
    "$$\n",
    "\\mathcal{L}_G = - \\mathbb{E}_{z \\sim p_z(z)}[\\log D(G(z))]\n",
    "$$\n",
    "\n",
    "つまり、ジェネレーターはディスクリミネーターに生成された画像を本物だと判定させるため、$ D(G(z)) $ を1に近づけるように損失を最小化しようとします。\n",
    "\n",
    "### 2. **cGANの損失関数**\n",
    "cGANは、通常のGANに「条件」を加えたモデルです。具体的には、ジェネレーターとディスクリミネーターの両方が「条件付き」で動作します。条件とは、例えば、生成する手書き数字のラベルです。GANの損失関数に「条件」を導入することで、損失関数は次のように変わります。\n",
    "\n",
    "#### 2.1 **ディスクリミネーターの損失関数**\n",
    "cGANでは、ディスクリミネーターは画像と条件ラベルのペアが本物か偽物かを判別します。そのため、ディスクリミネーターの損失関数は次のようになります。\n",
    "\n",
    "$$\n",
    "\\mathcal{L}_D = - \\mathbb{E}_{x, y \\sim p_{data}(x, y)}[\\log D(x, y)] - \\mathbb{E}_{z \\sim p_z(z), y \\sim p_{data}(y)}[\\log(1 - D(G(z, y), y))]\n",
    "$$\n",
    "\n",
    "ここで、\n",
    "- $ y $ は条件ラベル（例：生成したい手書き文字の数字）\n",
    "- $ D(x, y) $: 本物の画像 $ x $ と条件ラベル $ y $ のペアに対してディスクリミネーターが出力する確率（「本物」であると判定する確率）\n",
    "- $ G(z, y) $: ノイズ $ z $ と条件ラベル $ y $ から生成された偽物の画像\n",
    "- $ p_{data}(x, y) $: 実際のデータ（画像とラベルのペア）の分布\n",
    "\n",
    "この損失関数では、ディスクリミネーターは「画像とそのラベルが合っているか」という点も考慮して判断します。\n",
    "\n",
    "#### 2.2 **ジェネレーターの損失関数**\n",
    "ジェネレーターの目的は、条件ラベルに対応するリアルな画像を生成し、ディスクリミネーターに「本物」と判定させることです。したがって、ジェネレーターの損失関数は次のようになります。\n",
    "\n",
    "$$\n",
    "\\mathcal{L}_G = - \\mathbb{E}_{z \\sim p_z(z), y \\sim p_{data}(y)}[\\log D(G(z, y), y)]\n",
    "$$\n",
    "\n",
    "ジェネレーターは条件ラベル $ y $ に対応する画像 $ G(z, y) $ を生成し、そのペアがディスクリミネーターに「本物」と判断されるように学習します。\n",
    "\n",
    "### 3. **直感的な理解**\n",
    "- **ディスクリミネーター**: 与えられた条件（例：数字「5」）と画像を見て、「この画像は本物の手書きの5かどうか」を判定します。間違った数字に対して正しい画像が来た場合も「偽物」として判定します。\n",
    "- **ジェネレーター**: ラベルに基づいて画像を生成し、その生成された画像がディスクリミネーターに「本物」と判定されることを目指して学習します。\n",
    "\n",
    "### 4. **損失の最適化**\n",
    "学習の過程では、ディスクリミネーターとジェネレーターが交互に最適化されます。ディスクリミネーターは与えられた条件付きで本物と偽物を正確に見分けるように学習し、ジェネレーターは条件に基づいてリアルな画像を生成し、ディスクリミネーターを騙そうとします。\n",
    "\n",
    "cGANの学習が進むと、ジェネレーターは条件ラベルに忠実な画像を生成できるようになり、ディスクリミネーターもそれを判定する能力が向上します。このプロセスは、特定の条件付きで画像生成を行いたいタスクにおいて非常に効果的です。\n",
    "\n",
    "\n",
    "---（回答ここまで）---\n",
    "\n",
    "\n",
    "GANの説明と同じです．\n",
    "では，cGANコードを生成します．\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b75559-f722-46b8-bfd0-c766bb5d1efe",
   "metadata": {},
   "source": [
    "## 問題： Conditional Generative Adversarial Networksコードの作成\n",
    "\n",
    "敵対的生成ネットワーク（Generative Adversarial Networks（GAN））では生成モデルと識別モデルの2つのニューラルネットワークがお互いに競争しながら学習を進めます．\n",
    "以下の説明はデータとありますが，例えば，画像を指します．\n",
    "GANでは本物（実際のデータセットからのもの）と偽物（生成モデルが生成したもの）の２つを用います．\n",
    "\n",
    "- 生成モデル（Generator）は本物と見分けがつかない偽物のデータを生成します。通常、ランダムノイズから始まり、訓練後には本物に見えるデータを生成するよう訓練しますします．\n",
    "\n",
    "- 識別モデル（Discriminator）は、実画像を「本物」として、偽物画像を「偽物」として識別するように訓練します．\n",
    "\n",
    "分類問題のラベル（条件）を用いたGANも提案されています。\n",
    "Conditional GAN（cGAN）はラベル（条件）とそれに紐付いた画像の組が多数あると，ラベルから画像の生成するモデルを学習することができます．\n",
    "\n",
    "scikit-learnには0から9までの手書き文字画像（画像サイズ(8,8))とその答え（ラベル）を含むデータセット（digits）が用意されているので，\n",
    "このデータセットを用いてcGANを学習し、その生成したデータを利用して分類問題として学習を行うコードを生成して学習してください。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38d80b76-8576-4d30-b6c6-06aafb78607a",
   "metadata": {},
   "source": [
    "## 答え\n",
    "\n",
    "GANの簡単な応用問題で，単に\n",
    "\n",
    "1. ラベルの乱数への入れ方\n",
    "2. 識別器のラベルの識別方法\n",
    "\n",
    "が問題であると分かると思います．\n",
    "\n",
    "\n",
    "GANの場合\n",
    "```\n",
    "# Labels for real and fake data\n",
    "valid = torch.ones(batch_size_real, 1)\n",
    "fake = torch.zeros(batch_size_real, 1)\n",
    "\n",
    "# Discriminator loss on real and fake data\n",
    "real_loss = criterion(discriminator(real_data), valid)\n",
    "fake_loss = criterion(discriminator(fake_data.detach()), fake)\n",
    "```\n",
    "\n",
    "cGANの場合数字ラベルがある．0-0までのラベルがある場合にlossをどう定義するか？という問題．\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf65497f-d2f2-4a6e-8606-f1e2e77b58a2",
   "metadata": {},
   "source": [
    "## 第一段階\n",
    "\n",
    "GPTに尋ね人が学習しながらコード生成する例を示します．\n",
    "まず一般的な情報をGPTに求めてください．\n",
    "\n",
    "```\n",
    "プロンプト「\n",
    "cGANについて説明してください．\n",
    "」\n",
    "```\n",
    "\n",
    "回答をまとめると以下になります．\n",
    "\n",
    "---（回答）---\n",
    "\n",
    "一般的なGANは、無条件でデータを生成しますが、\n",
    "cGANでは、生成器と識別器の両方に条件付きの情報$ y $を追加します。具体的には次のようになります.\n",
    "- **Generator**: ノイズベクトル$ z $と条件$ y $を入力として受け取り、条件に基づいたデータを生成します。\n",
    "- **Discriminator**: 実データと生成データのどちらか、およびそのデータに対する条件を入力として受け取り、条件に一致する本物か偽物かを判別します。\n",
    "\n",
    "---（回答ここまで）---\n",
    "\n",
    "\n",
    "scikit-learnには0から9までの手書き文字画像（画像サイズ(8,8))とその答え（ラベル）を含むデータセット（digits）が用意されています。\n",
    "\n",
    "GANではラベルが正解「1」と不正解「0」だけでしたが，cGANは多数のラベルを持つのが異なることです．\n",
    "この段階ではどうなるのかわかりませんが，cGANはこれと似た形になるはずです．\n",
    "\n",
    "これをすでに説明したGANの枠組みで表すにはOnehotEncoding手法があります．\n",
    "\n",
    "OnehotEncodingとはラベル'0','1','2','3',...を，\n",
    "- ラベル'0'を(1,0,0,0,...)\n",
    "- ラベル'1'を(0,1,0,0,...)\n",
    "- ラベル'2'を(0,0,1,0,...)\n",
    "- ラベル'3'を(0,0,0,1,...)\n",
    "\n",
    "と要素数の長さ（0-9までなので10個）を持ち，各要素0 or 1で，該当要素のみ１を持つ，ベクトルで表す方法です．\n",
    "（GANでは，valid を(batch_size_real,1)の配列サイズとしました．）\n",
    "OnehotEncodingではvalid は(batch_size_real,10)とします．\n",
    "\n",
    "\n",
    "再びGPT4oに尋ねます．\n",
    "\n",
    "```\n",
    "プロンプト「\n",
    "cGANを作成します．\n",
    "識別モデルは、実画像を「本物」として、生成モデルが生成した画像を「偽物」として識別するために訓練する必要があります．\n",
    "ラベルは3つ以上のカテゴリがあります．ラベルをOnehotEncoderを用いてベクトルにします．\n",
    "生成モデルが生成した画像を「偽物」として識別するための損失関数について教えて下さい．\n",
    "」\n",
    "```\n",
    "\n",
    "---（回答）---\n",
    "\n",
    "torchのnn.BCEloss関数を用いて\n",
    "1. 本物の画像を本物と識別させるには識別器の出力と(1,1,1,...)ベクトルとBCEloss関数で計算します．\n",
    "2. 偽物の画像を偽物と識別させるには識別器の出力と(0,0,0,...)ベクトルとBCEloss関数で計算します．\n",
    "\n",
    "---（回答ここまで）---\n",
    "\n",
    "という回答がありました．\n",
    "本物と識別させる場合は，ラベルに関係なく必ず一致させるとしてラベル'0', ラベル'1',...を(1,1,1,...)と比較するという意味です．必ずどれかの要素と一致し，本物とし評価します．\n",
    "一方，(0,0,0,...)とはどれとも一致しないので，偽物と評価します．\n",
    "\n",
    "なお，実際に生成させたコードで本物と識別させるには(1,1,1,...)は良いベクトルではありませんでした．\n",
    "ラベルを具体的に用いて，ラベル'0'を(1,0,0,0,...)と表す方が良い結果になりました．\n",
    "（ネットワークとloss_D = real_loss + fake_lossの和のバランスの問題かもしれません．）\n",
    "\n",
    "## 第二段階\n",
    "\n",
    "物質科学でラベルがついた良い画像（二次元データ）例を持っていないので，\n",
    "まずは\n",
    "```\n",
    "プロンプト「\n",
    "scikit-learnには0から9までの手書き文字画像（画像サイズ(8,8))とその答え（ラベル）を含むデータセット（digits）が用意されています。\n",
    "このデータセットを用いてcGANをを行うコードを生成してください。\n",
    "Pytorchを用いてください．\n",
    "」\n",
    "```\n",
    "としてGPT4oにコード生成を依頼してみました．\n",
    "ここではニューラルネットワークライブラリとしてPytorchを指定しました．\n",
    "\n",
    "私が実行してみるとエラー修正依頼と，過程の可視化の指示が足りないことが分かります．\n",
    "エラー修正に関しては，GPTのプロンプトにエラーメッセージを貼り付けGPTに直してもらいます．\n",
    "また，lossが文字で表示され，どの程度妥当なGenenerator, Discriminatorが学習されたか判断できないので\n",
    "損失関数の履歴図と10エポック毎に生成された画像を出力の追加を依頼します．\n",
    "訓練データ，テストデータ部分のコードを読むと全データで学習しているのでそれらを分ける依頼を追加します．\n",
    "生成された画像はおかしい（数字文字では無い）ですが，ある程度の形のコードになるはずです．\n",
    "\n",
    "\n",
    "図をニューラルネットワークモデルの参考にしてください．図の本物，偽物の識別機は同じものです．\n",
    "![cGANの概念図](image_keep/cGAN_abstract.png)\n",
    "\n",
    "図：cGANの概念図．偽物生成器側の'3'の右側のベクトルはOnehotEncodingされたベクトルを示す．\n",
    "識別器の右側の出力もOnehotEncodingされたベクトルを示す．\n",
    "\n",
    "## 第三段階"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da5d15e-2113-4bf7-bb9c-4342631fe6c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
